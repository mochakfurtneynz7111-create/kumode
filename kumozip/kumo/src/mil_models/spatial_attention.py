"""
Spatial-Aware Attention Module

å®ç°ç»“åˆç‰¹å¾ç›¸ä¼¼åº¦å’Œç©ºé—´è·ç¦»çš„æ³¨æ„åŠ›æœºåˆ¶
ç”¨äºLeidenåŸå‹è¡¨ç¤ºçš„ç©ºé—´æ„ŸçŸ¥å»ºæ¨¡

Author: Based on DMSS paper architecture
Date: 2025-01
"""

import torch
import torch.nn as nn
import numpy as np


class SpatialAwareAttention(nn.Module):
    """
    ç©ºé—´æ„ŸçŸ¥æ³¨æ„åŠ›å±‚
    
    æ ¸å¿ƒæ€æƒ³ï¼š
    1. è®¡ç®—ç‰¹å¾æ³¨æ„åŠ›åˆ†æ•°ï¼ˆQÂ·K^Tï¼‰
    2. åˆ©ç”¨åŸå‹çš„ç©ºé—´åæ ‡è®¡ç®—ç©ºé—´ç›¸ä¼¼åº¦
    3. åŠ æƒèåˆï¼šattn = (1-Î±)*feat_attn + Î±*spatial_attn
    
    Args:
        dim (int): ç‰¹å¾ç»´åº¦
        spatial_centers (np.ndarray): åŸå‹ç©ºé—´åæ ‡ (n_proto, 2)
        heads (int): å¤šå¤´æ³¨æ„åŠ›çš„å¤´æ•°
        spatial_weight (float): ç©ºé—´æƒé‡åˆå§‹å€¼ï¼ˆä¼šå˜æˆå¯å­¦ä¹ å‚æ•°ï¼‰
        spatial_sigma (float): é«˜æ–¯æ ¸çš„sigmaï¼ˆæ§åˆ¶ç©ºé—´ç›¸ä¼¼åº¦è¡°å‡é€Ÿåº¦ï¼‰
    
    Example:
        >>> spatial_centers = np.random.rand(400, 2) * 1000
        >>> attn = SpatialAwareAttention(dim=512, spatial_centers=spatial_centers)
        >>> x = torch.randn(2, 401, 512)  # (batch, 1+n_proto, dim)
        >>> out = attn(x)
    """
    
    def __init__(self, dim, spatial_centers, heads=8, 
                 spatial_weight=0.3, spatial_sigma=None):
        super(SpatialAwareAttention, self).__init__()
        
        self.dim = dim
        self.heads = heads
        self.head_dim = dim // heads
        self.scale = self.head_dim ** -0.5
        
        assert dim % heads == 0, f"dim ({dim}) must be divisible by heads ({heads})"
        
        # QKVæŠ•å½±å±‚
        self.qkv = nn.Linear(dim, dim * 3, bias=False)
        self.proj = nn.Linear(dim, dim)
        
        # LayerNormï¼ˆç”¨äºæ®‹å·®è¿æ¥ï¼‰
        self.norm = nn.LayerNorm(dim)
        
        # === ğŸ”¥ ç©ºé—´ç›¸ä¼¼åº¦è®¡ç®— ===
        n_proto = spatial_centers.shape[0]
        spatial_centers_tensor = torch.from_numpy(spatial_centers).float()
        
        # è®¡ç®—ç©ºé—´æ¬§æ°è·ç¦»çŸ©é˜µ
        spatial_dist = torch.cdist(spatial_centers_tensor, spatial_centers_tensor)
        # spatial_dist shape: (n_proto, n_proto)
        
        # è‡ªé€‚åº”ç¡®å®šsigmaï¼ˆå¦‚æœæœªæŒ‡å®šï¼‰
        if spatial_sigma is None:
            spatial_sigma = spatial_dist.mean().item()
            if spatial_sigma < 1e-6:
                spatial_sigma = 1.0  # é˜²æ­¢é™¤é›¶
        
        # ğŸ”¥ ä½¿ç”¨é«˜æ–¯æ ¸å°†è·ç¦»è½¬æ¢ä¸ºç›¸ä¼¼åº¦
        # similarity = exp(-distance^2 / (2 * sigma^2))
        spatial_sim = torch.exp(-spatial_dist ** 2 / (2 * spatial_sigma ** 2))
        
        # å½’ä¸€åŒ–åˆ° [0, 1] èŒƒå›´
        max_sim = spatial_sim.max()
        if max_sim > 1e-6:
            spatial_sim = spatial_sim / max_sim
        
        # ğŸ”¥ æ‰©å±•ä»¥åŒ…å« cls_token
        # æœ€ç»ˆçŸ©é˜µå¤§å°: (n_proto+1, n_proto+1)
        extended_spatial = torch.zeros(n_proto + 1, n_proto + 1)
        extended_spatial[0, :] = 1.0  # cls_token ä¸æ‰€æœ‰tokenå…¨è¿æ¥
        extended_spatial[:, 0] = 1.0
        extended_spatial[1:, 1:] = spatial_sim  # åŸå‹éƒ¨åˆ†ä½¿ç”¨ç©ºé—´ç›¸ä¼¼åº¦
        
        # æ³¨å†Œä¸ºbufferï¼ˆä¸å‚ä¸æ¢¯åº¦æ›´æ–°ï¼‰
        self.register_buffer('spatial_similarity', extended_spatial)
        
        # ğŸ”¥ å¯å­¦ä¹ çš„ç©ºé—´æƒé‡
        # ä½¿ç”¨logitå½¢å¼ï¼Œé€šè¿‡sigmoidæ˜ å°„åˆ°[0,1]
        initial_logit = self._inverse_sigmoid(spatial_weight)
        self.spatial_weight_logit = nn.Parameter(torch.tensor(initial_logit))
        
        # ä¿å­˜é…ç½®ä¿¡æ¯
        self.n_proto = n_proto
        self.spatial_sigma = spatial_sigma
        
        print(f"[SpatialAwareAttention] Initialized")
        print(f"  - Number of prototypes: {n_proto}")
        print(f"  - Spatial sigma: {spatial_sigma:.2f}")
        print(f"  - Initial spatial weight: {spatial_weight:.3f}")
        print(f"  - Attention heads: {heads}")
    
    @staticmethod
    def _inverse_sigmoid(x):
        """sigmoidçš„åå‡½æ•°ï¼Œç”¨äºåˆå§‹åŒ–logit"""
        x = np.clip(x, 1e-6, 1 - 1e-6)
        return np.log(x / (1 - x))
    
    def forward(self, x):
        """
        å‰å‘ä¼ æ’­
        
        Args:
            x (torch.Tensor): è¾“å…¥ç‰¹å¾ (B, N, D)
                - B: batch size
                - N: åºåˆ—é•¿åº¦ = 1(cls_token) + n_proto + padding
                - D: ç‰¹å¾ç»´åº¦
        
        Returns:
            torch.Tensor: è¾“å‡ºç‰¹å¾ (B, N, D)
        """
        B, N, D = x.shape
        
        # === 1. QKVæŠ•å½±å’Œé‡å¡‘ ===
        qkv = self.qkv(x)  # (B, N, 3*D)
        qkv = qkv.reshape(B, N, 3, self.heads, self.head_dim)
        qkv = qkv.permute(2, 0, 3, 1, 4)  # (3, B, heads, N, head_dim)
        q, k, v = qkv[0], qkv[1], qkv[2]
        
        # === 2. è®¡ç®—ç‰¹å¾æ³¨æ„åŠ›åˆ†æ•° ===
        attn_feat = (q @ k.transpose(-2, -1)) * self.scale
        # attn_feat shape: (B, heads, N, N)
        
        # === 3. æ„å»ºç©ºé—´æ³¨æ„åŠ› ===
        n_valid = self.spatial_similarity.shape[0]  # cls + n_proto
        
        if N >= n_valid:
            # å¤„ç†paddingæƒ…å†µ
            spatial_attn = torch.zeros(N, N, device=x.device, dtype=x.dtype)
            
            # æœ‰æ•ˆéƒ¨åˆ†ä½¿ç”¨é¢„è®¡ç®—çš„ç©ºé—´ç›¸ä¼¼åº¦
            spatial_attn[:n_valid, :n_valid] = self.spatial_similarity
            
            # paddingéƒ¨åˆ†ï¼šåªä¸è‡ªå·±è¿æ¥ï¼ˆå¯¹è§’çŸ©é˜µï¼‰
            if N > n_valid:
                spatial_attn[n_valid:, n_valid:] = torch.eye(
                    N - n_valid, device=x.device, dtype=x.dtype
                )
        else:
            # å¦‚æœN < n_validï¼ˆç†è®ºä¸Šä¸ä¼šå‘ç”Ÿï¼‰
            spatial_attn = self.spatial_similarity[:N, :N]
        
        # === 4. ğŸ”¥ æ··åˆç‰¹å¾å’Œç©ºé—´æ³¨æ„åŠ› ===
        # è·å–å½“å‰çš„ç©ºé—´æƒé‡ï¼ˆå¯å­¦ä¹ ï¼‰
        alpha = torch.sigmoid(self.spatial_weight_logit)
        
        # æ··åˆå…¬å¼ï¼šattn = (1-Î±)*feat + Î±*spatial
        # spatial_attnéœ€è¦æ‰©å±•åˆ° (B, heads, N, N)
        spatial_attn_expanded = spatial_attn.unsqueeze(0).unsqueeze(0)
        
        attn = (1 - alpha) * attn_feat + alpha * spatial_attn_expanded
        
        # === 5. Softmaxå½’ä¸€åŒ– ===
        attn = attn.softmax(dim=-1)
        # attn shape: (B, heads, N, N)
        
        # === 6. åŠ æƒèšåˆ ===
        out = attn @ v  # (B, heads, N, head_dim)
        out = out.transpose(1, 2)  # (B, N, heads, head_dim)
        out = out.reshape(B, N, D)  # (B, N, D)
        
        # === 7. è¾“å‡ºæŠ•å½± ===
        out = self.proj(out)
        
        # === 8. æ®‹å·®è¿æ¥ ===
        out = out + self.norm(x)
        
        return out
    
    def get_spatial_weight(self):
        """
        è·å–å½“å‰çš„ç©ºé—´æƒé‡å€¼ï¼ˆç”¨äºç›‘æ§å’Œè°ƒè¯•ï¼‰
        
        Returns:
            float: å½“å‰ç©ºé—´æƒé‡ï¼ŒèŒƒå›´[0, 1]
        """
        return torch.sigmoid(self.spatial_weight_logit).item()
    
    def extra_repr(self):
        """é¢å¤–çš„æ¨¡å—ä¿¡æ¯ï¼Œç”¨äºprint(model)"""
        return f'dim={self.dim}, heads={self.heads}, n_proto={self.n_proto}, ' \
               f'spatial_weight={self.get_spatial_weight():.3f}'


# ============================================================
# å¯é€‰ï¼šè½»é‡çº§ç‰ˆæœ¬ï¼ˆå¦‚æœæ–¹æ¡ˆAå¤ªé‡æˆ–é‡åˆ°é—®é¢˜ï¼‰
# ============================================================

class SpatialBiasedAttention(nn.Module):
    """
    è½»é‡çº§ç©ºé—´åç½®æ³¨æ„åŠ›
    
    åœ¨æ ‡å‡†æ³¨æ„åŠ›åŸºç¡€ä¸Šæ·»åŠ ç©ºé—´è·ç¦»åç½®ï¼Œè€Œä¸æ˜¯å®Œå…¨æ··åˆ
    è®¡ç®—é‡æ›´å°ï¼Œä½†æ•ˆæœå¯èƒ½ç•¥é€ŠäºSpatialAwareAttention
    
    Args:
        dim (int): ç‰¹å¾ç»´åº¦
        spatial_centers (np.ndarray): åŸå‹ç©ºé—´åæ ‡ (n_proto, 2)
        heads (int): å¤šå¤´æ³¨æ„åŠ›çš„å¤´æ•°
        bias_strength (float): ç©ºé—´åç½®å¼ºåº¦
    """
    
    def __init__(self, dim, spatial_centers, heads=8, bias_strength=0.1):
        super(SpatialBiasedAttention, self).__init__()
        
        self.dim = dim
        self.heads = heads
        self.head_dim = dim // heads
        self.scale = self.head_dim ** -0.5
        
        assert dim % heads == 0, f"dim ({dim}) must be divisible by heads ({heads})"
        
        self.qkv = nn.Linear(dim, dim * 3, bias=False)
        self.proj = nn.Linear(dim, dim)
        self.norm = nn.LayerNorm(dim)
        
        # è®¡ç®—ç©ºé—´åç½®
        n_proto = spatial_centers.shape[0]
        spatial_centers_tensor = torch.from_numpy(spatial_centers).float()
        spatial_dist = torch.cdist(spatial_centers_tensor, spatial_centers_tensor)
        
        # è½¬æ¢ä¸ºåç½®é¡¹ï¼ˆè·ç¦»è¶Šè¿‘ï¼Œåç½®è¶Šå¤§ï¼‰
        # å½’ä¸€åŒ–åˆ° [-1, 0] èŒƒå›´
        max_dist = spatial_dist.max()
        if max_dist > 1e-6:
            spatial_bias = -spatial_dist / max_dist
        else:
            spatial_bias = torch.zeros_like(spatial_dist)
        
        spatial_bias = spatial_bias * bias_strength  # æ§åˆ¶å¼ºåº¦
        
        # æ‰©å±•åŒ…å«cls_token
        extended_bias = torch.zeros(n_proto + 1, n_proto + 1)
        extended_bias[1:, 1:] = spatial_bias
        
        self.register_buffer('spatial_bias', extended_bias)
        self.n_proto = n_proto
        
        print(f"[SpatialBiasedAttention] Initialized")
        print(f"  - Number of prototypes: {n_proto}")
        print(f"  - Bias strength: {bias_strength:.3f}")
        print(f"  - Attention heads: {heads}")
    
    def forward(self, x):
        """
        Args:
            x (torch.Tensor): (B, N, D)
        
        Returns:
            torch.Tensor: (B, N, D)
        """
        B, N, D = x.shape
        
        qkv = self.qkv(x).reshape(B, N, 3, self.heads, self.head_dim)
        qkv = qkv.permute(2, 0, 3, 1, 4)
        q, k, v = qkv[0], qkv[1], qkv[2]
        
        # ç‰¹å¾æ³¨æ„åŠ›
        attn = (q @ k.transpose(-2, -1)) * self.scale
        
        # ğŸ”¥ æ·»åŠ ç©ºé—´åç½®
        n_valid = self.spatial_bias.shape[0]
        if N >= n_valid:
            bias = torch.zeros(N, N, device=x.device, dtype=x.dtype)
            bias[:n_valid, :n_valid] = self.spatial_bias
            
            # paddingéƒ¨åˆ†ä¸æ·»åŠ åç½®
            attn = attn + bias.unsqueeze(0).unsqueeze(0)
        
        attn = attn.softmax(dim=-1)
        
        out = (attn @ v).transpose(1, 2).reshape(B, N, D)
        out = self.proj(out)
        
        return out + self.norm(x)
    
    def extra_repr(self):
        return f'dim={self.dim}, heads={self.heads}, n_proto={self.n_proto}'


# ============================================================
# æµ‹è¯•ä»£ç 
# ============================================================

if __name__ == "__main__":
    print("=" * 60)
    print("Testing SpatialAwareAttention")
    print("=" * 60)
    
    # åˆ›å»ºå‡æ•°æ®
    batch_size = 2
    n_proto = 400
    dim = 512
    
    # æ¨¡æ‹ŸåŸå‹ç©ºé—´åæ ‡ï¼ˆåœ¨1000x1000çš„å›¾åƒä¸Šï¼‰
    np.random.seed(42)
    spatial_centers = np.random.rand(n_proto, 2) * 1000
    
    # åˆå§‹åŒ–æ¨¡å—
    attn = SpatialAwareAttention(
        dim=dim,
        spatial_centers=spatial_centers,
        heads=8,
        spatial_weight=0.3
    )
    
    # åˆ›å»ºè¾“å…¥ï¼ˆåŒ…å«cls_tokenï¼‰
    x = torch.randn(batch_size, n_proto + 1, dim)
    
    print(f"\nInput shape: {x.shape}")
    print(f"Initial spatial weight: {attn.get_spatial_weight():.4f}")
    
    # å‰å‘ä¼ æ’­
    try:
        out = attn(x)
        print(f"âœ… Forward pass successful!")
        print(f"Output shape: {out.shape}")
        
        # æ£€æŸ¥è¾“å‡ºå½¢çŠ¶
        assert out.shape == x.shape, "Output shape mismatch!"
        print("âœ… Shape verification passed!")
        
    except Exception as e:
        print(f"âŒ Forward pass failed: {e}")
        import traceback
        traceback.print_exc()
    
    print("\n" + "=" * 60)
    print("Testing SpatialBiasedAttention")
    print("=" * 60)
    
    # æµ‹è¯•è½»é‡çº§ç‰ˆæœ¬
    attn_lite = SpatialBiasedAttention(
        dim=dim,
        spatial_centers=spatial_centers,
        heads=8,
        bias_strength=0.1
    )
    
    try:
        out_lite = attn_lite(x)
        print(f"âœ… Lite version forward pass successful!")
        print(f"Output shape: {out_lite.shape}")
        
    except Exception as e:
        print(f"âŒ Lite version forward pass failed: {e}")
    
    print("\n" + "=" * 60)
    print("All tests completed!")
    print("=" * 60)